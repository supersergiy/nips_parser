# -*- coding: utf-8 -*-
import scrapy


OUTPUT_FILE_PATH = './2017_nips.csv'
class NipsSpider(scrapy.Spider):
    name = "nips"
    def __init__(self, *args):
        super(NipsSpider, self).__init__()
        self.output_file = file.open(OUTPUT_FILE_PATH, 'w')
        self.output_file.write('Year, Name, Event Type, PDF Link, ' +
                                'NIPS Link, Abstract, Citation, Authors
    def start_requests(self):
        urls = [
            'https://papers.nips.cc/book/advances-in-neural-information-processing-systems-30-2017',
        ]
        for url in urls:
            yield scrapy.Request(url=url, callback=self.parse)

    def parse(self, response):
	heading = response.css('title::text')[0].extract()
        if heading == 'NIPS 2017 Proceedings':
            self.log('Parsing the head page')
            for item in response.css('li')[1:]:
                paper_suffix = item.css('a::attr(href)').extract()[0]
                paper_link   = response.urljoin(paper_suffix)
                self.log('Found paper! {}'.format(paper_link))
                yield response.follow(paper_link, callback=self.parse)
        else:
            self.log('Parsing a paper page')
            import pdb; pdb.set_trace()
	print (heading)

        '''page = response.url.split("/")[-2]
        filename = 'quotes-%s.html' % page
        with open(filename, 'wb') as f:
            f.write(response.body)
        self.log('Saved file %s' % filename)'''
